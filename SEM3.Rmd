---
title: "Understanding Implied Structure in Past COVID-19 Research using SEM and CFA"
author: "Joshua McCarthy"
date: "01/07/2020"
output: 
  md_document:
    variant: markdown_strict+backtick_code_blocks
bibliography: ref.bib
csl: harvard-uts.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.path='Figs/', class.output = "chunk-output",
                      echo=TRUE, warning=FALSE, message=FALSE)
```

```{r libraries, warning=FALSE, error=FALSE, message=FALSE}
library(tidyverse)
library(lavaan)
library(lubridate)
library(visdat)
library(dagitty)
library(janitor)
library(cowplot)
library(scales)
library(semPlot)
library(gfoRmula)
library(ggdag)
library(semTools)
library(data.table)
```
# Intent


## Aim
The teamâ€™s previous research into the COVID-19 pandemic attempted to understand how different variables observations related, if correlation existed between these observations, and draw conclusions about these correlations. The conclusions were generally communicated in the terms of cause and effect, though the complexities of the topic were unknown at the time. [@dannyleihanCOVID19COVIDResearch202007272020]

The research was undertaken based on assumptions and observations about how the different variables may interact. The team shared their assumptions, asking questions to define how these variables might be related, and their findings, reinforcing the perception of cause and effect. Throughout the project, an uncommunicated, shared understanding for a potential relationship between the many variables was implied and developed, at the time the team only had the comparatively simple tool of linear regression to evaluate weather two variables were or were not related, error and potential reasons for strange results could not be directly attributed to a single cause.

Causal inference provides a framework to visualise, assess and communicate the structure implied throughout the research and understand how error, systematic bias, could have affected the results [@hernanCausalInferenceWhat]. Further, Structural Equation Modelling (SEM) enables us to test these structures, observing how well they reflect the observational data, and therefore how well our assumptions may fit to the actual interactions taking place. These tools can be applied together to identify if the lack of clear outcomes was potentially due to a misunderstanding of the causal pathways involved related to the pandemic and the observations captured.

## Research Questions
1. What are the structures and causal pathways implied in the previous research?
2. How may systemic bias affected the previous research?
3. How well does this structure reflect the observational data obtained?
4. Can we identify a structure that more accurately reflects the observational data?

## Rational
Any attempts to draw conclusions from, or further, our previous research, will be built upon the causal structure developed within the project. Fundamental flaws and bias will proliferate through subsequent research attempts, reinforced by any, potentially inaccurate, findings of the previous work. Evaluating the accuracy of the implied structure enables us to understand whether the outcomes or lack of outcomes was due to actual associations within the data or due to incorrect structure and/or bias. Identifying how systemic bias may have affected the research undertaken will enable future research project to apply methods more appropriate to negating these issues. Identifying a more accurate model will further benefit these efforts, providing a starting point for projects to be more successful.

#### Errors
It should be noted that while diligence has been attempted, I am by no means an expert in any of the topics addressed in this document, errors in interpretation are likely. The repository for this report will be made public [on GitHub here](https://github.com/jsmccid/STDS-AT3/) once marked. If any errors are identified, please raise them as issues on GitHub or feel free to make modifications yourself and submit a pull request. Assistance here is greatly appreciated as this is an interesting and complex field, this work represents a first learning experience with many of the concepts presented.

# Implied Structure
The structures implied by the previous research are collated in [Appendix A](#appendix-a). With approximately 69 implications observable in the project a complex causal structure has developed, visualised below by sections. These structures are represented as Directed Acyclic Graphs (DAG). Causal inference implies the need to understand the True DAG in order to infer a causal relationship, prior to this, a collection of causal stories or hypothesised DAGs can be used to test theories against, with the understanding that some unidentified bias may still be present. [@harvardxph559xCausalDiagramsDraw2020]. A breakdown of the DAGs implied by each section and the bias introduced is available in [Appendix B](#appendix-b)

## Simplified DAG
The below DAG attempts to simplify the implied structure into a model that can be interpreted using SEM with the available data. This model does not include any unobserved / latent variables that do not have an associated measurement as second order latent variables can be problematic to the model [@HowWouldSet], fortunately unmeasured factors as a source of error is inherently assumed by SEM modelling. The patient based research cannot be fully emulated along with the other country based analysis, however, some chronic risk factors are available in country level data. Similarly, the apple mobility data was not available to join with the dataset. When making our prior implications we did not imply covariances amongst our measurements so, so none are present in the DAG.

![DAG](./dags/dagsimp.png)

# Data
The datasets to be utilised are:
* Our World in Data COVID Dataset [@ourworldindataOwidCovid19data2020]
* Oxford Covid-19 Government Response Tracker [@OxCGRTCovidpolicytracker2020a]
* Trust in Politicians from the Institutional Profiles Database[@InstitutionalProfilesDatabase]
* Government Effectiveness from Worldbank [@WGI2019Interactive]
* Health equality and basic healthcare from GovData360 [@GovData360HealthEquality]

```{r data_download, eval = FALSE}
# COVID OWID
download.file("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv", "./data/covid_owid.csv")

# OxCGRT
download.file("https://github.com/OxCGRT/covid-policy-tracker/raw/master/data/OxCGRT_latest.csv", "./data/oxpol.csv")
```

```{r owid_lubridate_vis}
# add inciremental weeks and months to the data
covid <- read.csv("./data/covid_owid.csv")
covid$month <- lubridate::month(covid$date, label = TRUE, abbr = TRUE)
covid$week <- lubridate::week(covid$date)
covid$week <- covid$week+1
covid[covid$week == 54, "week"] <- 1 

#available data
names(covid)

#visualise missing data
vis_dat(covid, warn_large_data = FALSE)
```
Visualising the OWID data shows that records of testing numbers are quite sparse, and unlikely to be useful in the analysis.

To reduce the noise in the variables the OWID dataset is summarised by week.
```{r summarise_owid, warning = FALSE, message = FALSE}

coviddata_sumweek <- covid %>%
  filter(location != "World", location != "International") %>% 
  group_by(iso_code, week) %>% 
  summarise(
            week_start = first(date),
            week_end = last(date),
            new_cases = sum(new_cases),
            new_deaths = sum(new_deaths),
            new_cases_per_million = sum(new_cases_per_million),
            new_deaths_per_million = sum(new_deaths_per_million),
            new_tests = sum(new_tests),
            new_tests_per_thousand = sum(new_tests_per_thousand),
            ) %>% 
  ungroup()

join <- covid %>% 
  select(-new_cases, -new_deaths, -new_cases_per_million, -new_deaths_per_million, -new_tests, -new_tests_per_thousand, -week) %>% 
  mutate(week_end = date)

coviddata_sumweek<- merge(coviddata_sumweek, join, by = c("iso_code", "week_end"))
```

The additional metric datasets are imported and joined with the OWID dataset, the same method as in the previous project.
```{r add_data, warning = FALSE, message = FALSE}
poltrustfull <- read_csv("./data/poltrustfull.csv")

poltrustfull <- poltrustfull %>%
  mutate(iso_code = country_iso3) %>% 
  select(iso_code, x2018)
names(poltrustfull)[2] <- "trust_in_pol"

coviddata_m <- merge(coviddata_sumweek, poltrustfull, by = "iso_code")

#government effectiveness
gov_effect <- read_csv("./data/goveffect.csv")
gov_effect <- clean_names(gov_effect)
goveff <- gov_effect %>% 
  filter(indicator == "Government Effectiveness", subindicator_type == "Estimate") %>% 
  mutate(iso_code = country_iso3) %>% 
  select(iso_code, x2018)
names(goveff)[2] <- "government_eff"

coviddata_m <- merge(coviddata_m, goveff, by = "iso_code")

glostatedemoc <- read_csv("./data/globalstatedemoc.csv")
glostatedemoc <- clean_names(glostatedemoc)

glostat_health <- glostatedemoc %>% 
  filter(indicator == "Health equality" | indicator == "Basic welfare") %>% 
  mutate(iso_code = country_iso3) %>% 
  select(iso_code, indicator, x2018) %>% 
  pivot_wider(names_from = indicator, values_from = x2018) %>% 
  clean_names()

coviddata_m <- merge(coviddata_m, glostat_health, by = "iso_code")
```

# Modelling
Structural equation modelling comes with a variety of challenges, the foremost is ensuring that the model is identified, there are a variety of tests to ensure a model is identified however the simplest method is to create a recursive model. A recursive model is directional, reflecting a DAG, as such the models used are all intended to be recursive models. [@thakkarStructuralEquationModelling2020]. A core challenge to this effort is that by measuring between countries, for non-time-varying models we are limited to a maximum of ~200 observations, this is very near the lower limit for data size for SEM, and for our initial model, below the suggested number of observations. As joining data from external sources was required, the number observations was further decreased reducing the chances of success and model convergence.

```{r total_death_filter, warning = FALSE}
cvd_week5dplus <- coviddata_m %>% 
  group_by(iso_code) %>% 
  mutate(stringency_index = max(na.omit(stringency_index))) %>% 
  ungroup() %>%
  filter(total_deaths >= 5) %>% #filter
  group_by(iso_code) %>% 
  mutate(sincefive = row_number()) %>% #counting weeks
  filter(total_deaths == max(total_deaths)) %>% 
  filter(date == min(date)) %>% 
  ungroup() %>% 
  filter(stringency_index > -1000, total_deaths > -1000)
```

## Data Checking
Originally SEM relied on all multivariate distributions being normal, where possible this is still recommended, however robust estimator methods have been developed to handle non-normal distributions.
```{r check_distribs1}
# https://stackoverflow.com/questions/48507378/plotting-distributions-of-all-columns-in-an-r-data-frame
cvd_vars <- cvd_week5dplus %>% 
  select(location, total_cases_per_million, total_deaths_per_million, population, population_density, aged_65_older, aged_70_older, median_age, cvd_death_rate, diabetes_prevalence, stringency_index, government_eff, trust_in_pol, gdp_per_capita, hospital_beds_per_thousand, basic_welfare, health_equality) %>% 
  filter(stringency_index >= 0) %>% 
  na.omit()


dist_plots <- lapply(names(cvd_vars), function(var_x){
  p <- 
    ggplot(cvd_vars) +
    aes_string(var_x)

  if(is.numeric(cvd_vars[[var_x]])) {
    p <- p + geom_density()

  } else {
    p <- p + geom_bar()
  } 

})

plot_grid(plotlist = dist_plots)

ggplot(cvd_vars, aes(x = total_cases_per_million, y = total_deaths_per_million)) + geom_point() + geom_label(aes(label = location))

summary(cvd_vars$total_cases_per_million)
summary(cvd_vars$total_deaths_per_million)
```
There is variation in distributions so a robust method must be selected. "MLR" is a recommended starting point if data quality is questionable. [@michaelhallquistIntroductorySEMUsing2018]

SEM is more effective when the data has had outliers removed, Belgium and Qatar represent outliers in cases and deaths per million respectively and have been removed. [@thakkarStructuralEquationModelling2020]. Similarly, Singapore, India and China have been removed due to their exceptionally high population.
```{r check_distribs2}
cvd_vars <- cvd_vars %>% 
  filter(location != "Belgium", location != "Qatar") %>% 
  filter(total_cases_per_million >= 200, total_deaths_per_million >= 3)

ggplot(cvd_vars, aes(x = population, y = population_density)) + geom_point() + geom_label(aes(label = location), vjust = -2)

cvd_vars <- cvd_vars %>% 
  filter(location != "Singapore", location != "India", location != "China")

dist_plots <- lapply(names(cvd_vars), function(var_x){
  p <- 
    ggplot(cvd_vars) +
    aes_string(var_x)

  if(is.numeric(cvd_vars[[var_x]])) {
    p <- p + geom_density()

  } else {
    p <- p + geom_bar()
  } 

})

plot_grid(plotlist = dist_plots)

summary(cvd_vars)
```

Despite removing some outliers and a portion of the lowest values the distributions are still quite skewed for some statistics, the robust estimator functions may mitigate this in part. Additionally, the total number of observations has continued to decrease, however as this is the effort for evaluating the initial structure so we will proceed with the analysis.


## Specify Structure
The DAG is now represented in Lavaan SEM format, latent variables represent the structure of our DAG and the data collected is used as measures of these latent variables.
```{r initial_structure}
init_model <- '
# latent variable model
pop_factors =~ population_density + population
age_risk =~ aged_65_older + aged_70_older + median_age
chronic_risk =~ cvd_death_rate + diabetes_prevalence
cases =~ total_cases_per_million
deaths =~ total_deaths_per_million
response_eff =~ trust_in_pol + government_eff + stringency_index
healthcare =~ basic_welfare + health_equality + hospital_beds_per_thousand


# regressions
cases ~ pop_factors + age_risk + response_eff
deaths ~ cases + age_risk + chronic_risk + healthcare

# covariance
chronic_risk ~~ age_risk
healthcare ~~ age_risk
aged_65_older ~~ aged_70_older
'
```

Lavaan produced and error and struggles to converge when variance between variables is large, as such the variables have been rescaled according to their distributions on a smaller scale.
```{r rescale_intial}
cvd_vars <- cvd_vars %>% 
  mutate_at(vars(-location), rescale, to = c(0,1))
```

When gradient check is active the model appears to have converged but there most variances and errors are NA, setting to false prevents some of this error.
```{r intial_model}
cvd_sem <- sem(init_model, data = cvd_vars, estimator = "MLR", check.gradient = FALSE)
```
Negative variance is often a sign of an unidentified model, however as the model should be recursive this is unlikely to be the case, more likely is that the structure is too different from what the data represents and there is not possible solution, thus negative variances have to be introduced in order to enable fitting to occur, unfortunately negative variances indicate a failed model [@rosseelStructuralEquationModeling].

## Research Evaluation
As is evident from the analysis of the DAGs and SEM the structure implied in the previous research was unlikely to produce a positive outcome and is unlikely to represent the observations available in the data. This is likely partly due to the choice to use countries for evaluation, and the large count of endogenous variables in this model represented by variables that are regressed by another variable. Further efforts to modify this structure are unlikely to be fruitful and not best practice [@BestPracticesSEM].

# Build Up Approach and Confirmatory Factor Analysis (CFA)
A preferable alternative to the approach taken previously is to build up first a DAG, and then a model iterating informed by fit and variance [@BestPracticesSEM] to increase complexity and improve fit. An attempt at which is undertaken here. This attempt is still constrained by the data already collected but presents an opportunity to guide future investigation.

## Simplified DAG
If we assume measurement error is not present, we can create a simple DAG for the effect of age, this DAG presents an opportunity for CFA, the measurement error is still somewhat accounted for by the SEM model.
```{r acd_dag}
a <- dagify(cases ~ age,
            death ~ age,
            death ~ cases)
ggdag(a) + theme_dag()
```
The above DAG shows age as a parent of both cases and death, and cases as a parent of death, age is an exogenous variable, while cases and death are endogenous. While extremely simple, age is still a confounder in this DAG as a common cause of cases and death in any efforts to investigate the effects of cases on death. Deaths is the outcome variable, cases the contributing variable and age an exposure.

## New Outcome Variable
The previous research utilised total deaths and cumulative measures. Instead, the new outcome variable is created as the new_deaths_per_million, 4 weeks or 28 days after the first 100 cases. This allows the DAG to represent a non-time-varying snapshot of the pandemic. This allows time for gestation, and infection while also being on the upslope of many countries new case curves. Finally, to aid modelling the variance both new_cases_per_million and new_deaths_per_million will be log transformed.

```{r new_var, warning = FALSE, message = FALSE}
covid_new <- covid %>%
  filter(location != "World", location != "International") %>% 
  group_by(iso_code, week) %>% 
  summarise(
            week_start = first(date),
            week_end = last(date),
            new_cases = sum(new_cases),
            new_deaths = sum(new_deaths),
            new_cases_per_million = sum(new_cases_per_million),
            new_deaths_per_million = sum(new_deaths_per_million),
            new_tests = sum(new_tests),
            new_tests_per_thousand = sum(new_tests_per_thousand),
            stringency_index = mean(stringency_index)
            ) %>%
  ungroup()

join <- covid %>% 
  select(-new_cases, -new_deaths, -new_cases_per_million, -new_deaths_per_million, -new_tests, -new_tests_per_thousand, -week) %>% 
  mutate(week_end = date, -stringency_index)

covid_new_m <- merge(covid_new, join, by = c("iso_code", "week_end"))
```

```{r cases_vis}
ggplot(covid_new_m, aes(x = week, y = total_cases, color = location)) + geom_line()+ theme(legend.position = "none") + ylim(0, 2500)
```
This visualisation, though messy aided in the selection of an appropriate lower total case limit, looking for an figure that was near the beginnings of initial slop increases.

```{r case_select}
cvd_100c <- covid_new_m %>% 
  group_by(iso_code) %>%
  filter(total_cases >= 100) %>% 
  arrange(week) %>% 
  mutate(weekoneplus = row_number()) %>% 
  ungroup()

ggplot(cvd_100c, aes(x = weekoneplus, y = new_cases_per_million, color = location)) + geom_line()+ theme(legend.position = "none")+ ylim(0, 2000)
```
Again, not a clear visualisation but helpful in selecting a new_case_per_million value to reduce noise.

Log transformation of the variables induced unidentified values where they were zero which had to be rectified.
```{r}
cvd_100c_p4 <- cvd_100c %>% 
  group_by(iso_code) %>% 
  filter(weekoneplus == 4) %>% 
  ungroup() %>% 
  mutate(logndpm = log(new_deaths_per_million), logncpm = log(new_cases_per_million))

cvd_100c_p4[cvd_100c_p4$logndpm < -1000, "logndpm"] <- 0
cvd_100c_p4[cvd_100c_p4$logncpm < -1000, "logncpm"] <- 0

ggplot(cvd_100c_p4, aes(x = median_age, y = logndpm)) + geom_point()
ggplot(cvd_100c_p4, aes(x = median_age, y = logncpm)) + geom_point()
```
These visualisations show how log transformation improves the clarity of the signal in both new cases and new deaths.

```{r}
dist_plots <- lapply(list("logncpm", "logndpm", "aged_65_older", "aged_70_older", "median_age"), function(var_x){
  p <- 
    ggplot(cvd_100c_p4) +
    aes_string(var_x)

  if(is.numeric(cvd_100c_p4[[var_x]])) {
    p <- p + geom_density()

  } else {
    p <- p + geom_bar()
  } 

})

plot_grid(plotlist = dist_plots)
```
The distributions of our new variables are again visualised before deploying the SEM model, while they are less skewed than other variables utilised earlier, a robust estimator must still be utilised.

## CFA Model

### Model 1- Age, Cases, Deaths
Though cases is a much less reliable statistic than deaths due to measurement error differences in reporting and testing, etc [@ourworldindataOwidCovid19data2020], not including it in analysis leaves few other opportunities. As before, cases and deaths are latent variables of their measured outcomes which accounts for some of this error, age is a latent variable with three measures, median age of the country and proportions aged 65+ and aged 70+. Covariance between aged 65+ and aged 70+ is introduced due to their likely interaction.

```{r cfa1}
cfa1_df <- cvd_100c_p4 %>% 
  mutate_at(vars(median_age, aged_65_older, aged_70_older, logncpm, logndpm), rescale, to = c(0,10))

cfa1_model <-'
# latent variables
age_risk =~ aged_70_older + median_age + aged_65_older
cases =~ logncpm
deaths =~ logndpm

# regressions (effects)
cases ~ age_risk
deaths ~ age_risk + cases

#covariances
aged_65_older ~~ aged_70_older
'

cfa1_sem <- cfa(cfa1_model, data = cfa1_df, estimator = "MLR")
summary(cfa1_sem, fit.measures=TRUE, standardized=TRUE)
```
This time modelling produced no errors and the fit measures are valid. The output is quite long but can be addressed in sections. It should be noted that measures are taken as their robust variants which are less effected by non-normal distributions [@savaleiComputationRMSEACFI2018].

**Fit**
SEM fit is a very loosely defined subject with many competing recommendations, Gana and Broc detail this and provide their own interpretation which will be the basis for model fit evaluation [@ganaStructuralEquationModeling2018]. Chi Squared significance (CSS) and SRMR are suggested as the best indicator of absolute fit, the CSS value of 0.019 is below the 0.05 threshold indicating significance, unfortunately in SEM this indicates a poor fit. However, SRMR of 0.011 is well below the threshold suggested by G&B of 0.08 indicating a good fit. CFI and TLI indicate if the fit is better than the null model, for both indicators a value >0.95 indicates good fit. The model CFI 0.993 and TLI 0.977 are above this threshold indicating the model is a better fit than the null model. AIC and BIC are indicators of comparative fit between similar models, due to the large changes being undertaken between model iterations in this project are unlikely to be useful. Likelhood of RMSEA significance is low, the RMSEA itself is low, however so are the confidence interval bounds creating challenges in interpretation.

Overall, most fit indices indicate a good fit the DOF of the model is quite low and the sample quite small potentially contributing the issues with CSS values. The fit is not poor nor conclusive good either. 

**Coefficients and Variances**
The interpretation of coefficients and variances in SEM is more challenging due to the fixing of some variances and not other in the model, this behaviours can be modified but requires significant interrogation of the underlying causal structure for latent and total effects. For the above model, all variance estimates are reasonable within their ranges, age risk is quite high comparative to other variances but does not appear to be too unreasonable. Similarly, some of the free z-values are significant. This indicates there are no obvious errors within the model.


```{r cfa1_paths}
semPaths(cfa1_sem,  what = "stand", rotation = 2, layout = "tree")
```
Again the variance estimates can be visualised.

### Model 2 - Age, Cases, Chronic Illness, Deaths
```{r}
a <- dagify(covid ~ age,
            death ~ age,
            death ~ covid,
            chronic ~ age,
            death ~ chronic,
            exposure = "chronic",
            outcome = "death"
            )
ggdag(a) + theme_dag()
```
As the previous model indicated some goodness of fit, I have chosen to continue exploration, and incorporate further variables in order to asses the effect on the mode. The second iteration introduces risk due to chronic disease, measured by cardiovascular death rate and diabetes prevalence within the country. Increased age is associated with increased risk of cardiovascular  disease, and we can test if our inference that this is further associated with deaths was in the correct direction.

```{r}
cfa2_df <- cvd_100c_p4 %>% 
  mutate_at(vars(median_age, aged_65_older, aged_70_older, logncpm, logndpm, cvd_death_rate, diabetes_prevalence), rescale, to = c(0,10))

cfa2_model <-'
# latent variables
age_risk =~ aged_70_older + median_age + aged_65_older
cases =~ logncpm
deaths =~ logndpm
chronic_disease =~ cvd_death_rate + diabetes_prevalence

# regressions (effects)
cases ~ age_risk
deaths ~ age_risk + cases + chronic_disease


#covariances
aged_65_older ~~ aged_70_older
'

cfa2_sem <- cfa(cfa2_model, data = cfa2_df, estimator = "MLR")
```
Despite many attempts to modify the structure and measures, incorporating chronic disease risk as a latent variable induced negative variances in the model, similar to the initial model. Therefore, this model is a failure.

```{r}
semPaths(cfa2_sem,  what = "stand", rotation = 2, layout = "tree")
```
Here we can visualise where the negative variances occur.

### CFA Model 3
```{r cfa3_dag}

a <- dagify(cases ~ age,
            death ~ age,
            death ~ cases,
            cases ~ mitigation
            )
ggdag(a) + theme_dag()
```
This DAG introduces the latent exogenous variable mitigations, measured by stringency index, this variable is associated with an effect on cases, as cases are likely to be effected by changes in restrictions.

```{r cfa4_model}
cfa4_df <- cvd_100c_p4 %>% 
  mutate_at(vars(median_age, aged_65_older, aged_70_older, logncpm, logndpm, cvd_death_rate, diabetes_prevalence, stringency_index.x), rescale, to = c(0,10))

cfa4_model <-'
# latent variables
age_risk =~ aged_70_older + median_age + aged_65_older
cases =~ logncpm
deaths =~ logndpm
mitigation =~ stringency_index.x

# regressions (effects)
cases ~ age_risk + mitigation
deaths ~ age_risk + cases

#covariances
aged_65_older ~~ aged_70_older
'

cfa4_sem <- cfa(cfa4_model, data = cfa4_df, estimator = "MLR")
summary(cfa4_sem, fit.measures=TRUE, standardized=TRUE)
```
All fit measures are improved over the initial simplified model, though chi-squared is still within the significant range. This model is a better fit than the previous model overall, though still unlikely objectively good fit.

```{r cfa4_vis}
semPaths(cfa4_sem,  what = "stand", rotation = 2, layout = "tree")
```
Quite similar to previous models, however there is some negative covariance indicated between mitigations and age related risk that was not included in the SEM.

**Static Statistics**
Attempts were made to substitute in additional static statistics such as government effectiveness and healthcare however this often resulted in model errors or poorer fit.

## Time Varying Model
The previous model while still not showing a good fit overall does indicate that there is an improvement in fit when including mitigation factors. The previous DAG is quite unrealistic however as the relationship between these variables is time varying, as cases initially drove stringency, and then stringency effects subsequent case numbers. Developing a time-varying model induces significant bias that is difficult to overcome, requiring g-methods [@hernanCausalInferenceWhat], but may improve understanding of the structure.

![DAG](./dags/tvdag.png)

Here the DAG illustrates why time varying models are so challenging to manage systematic bias within. Additionally, as outlined by Hernan, there is often time-varying measurement error in such a model increasing complexity, this has not been included here [@hernanCausalInferenceWhat]. The above DAG illustrates the relationship between an initial state 0, and a subsequent state 1, this can be repeated n times. Below this state 0 is the state we have been utilising previously, and state 1 is an additional 4 weeks after state 0.

```{r}
cvd_100c_p8 <- cvd_100c %>% 
  filter(iso_code != "ECU", weekoneplus == 8) %>% 
  mutate(logndpm = log(new_deaths_per_million), logncpm = log(new_cases_per_million))

cvd_100c_p8[cvd_100c_p8$logndpm < -1000, "logndpm"] <- 0
cvd_100c_p8[cvd_100c_p8$logncpm < -1000, "logncpm"] <- 0

timevar <- merge(cvd_100c_p4, cvd_100c_p8, by = "iso_code")
```

```{r}
cfa_tv <- timevar %>% 
  mutate_at(vars(median_age.x, aged_65_older.x, aged_70_older.x, logncpm.x, logndpm.x, stringency_index.x.x,
                 median_age.y, aged_65_older.y, aged_70_older.y, logncpm.y, logndpm.y, stringency_index.x.y), rescale, to = c(0,10))

cfa_tv_model <-'
# latent variables
age_risk =~ aged_70_older.x + median_age.x + aged_65_older.x
cases0 =~ logncpm.x
cases1 =~ logncpm.y
deaths0 =~ logndpm.x
deaths1 =~ logndpm.y
mitigation0 =~ stringency_index.x.x
mitigation1 =~ stringency_index.x.y

# regressions (effects)

deaths1 ~ age_risk + cases1 + cases0
mitigation1 ~ cases0 + cases1 + mitigation0
cases1 ~ age_risk + mitigation0 + cases0
deaths0 ~ age_risk + cases0
mitigation0 ~ cases0
cases0 ~ age_risk

#covariances
aged_65_older.x ~~ aged_70_older.x
'

cfa_tv_sem <- sem(cfa_tv_model, data = cfa_tv, estimator = "MLR")
summary(cfa_tv_sem, fit.measures=TRUE, standardized=TRUE)
```
Somewhat surprisingly, there were no errors in processing the model. Unfortunately, model fit indicators are performing poorer, CSS is decreased and SRMR has increased above the 0.05 threshold. Comparative fit indices are reduced, though RMSEA is also reduced which is positive. A worthwhile test, but unfortunately not fully successful. 

```{r}
semPaths(cfa_tv_sem,  what = "stand", rotation = 2, layout = "tree")
```
As there were errors in processing the model it may be interesting if we assume there was no inititial mitigation, as there would have been at the start of the pandemic and modify the structure as such.

![DAG](./dags/tvdag2.png)

```{r}
cfa_tv_model <-'
# latent variables
age_risk =~ aged_70_older.x + median_age.x + aged_65_older.x
cases0 =~ logncpm.x
cases1 =~ logncpm.y
deaths0 =~ logndpm.x
deaths1 =~ logndpm.y
mitigation1 =~ stringency_index.x.y

# regressions (effects)

deaths1 ~ age_risk + cases1 + cases0
mitigation1 ~ cases0 + cases1
cases1 ~ age_risk  + cases0
deaths0 ~ age_risk + cases0
cases0 ~ age_risk

#covariances
aged_65_older.x ~~ aged_70_older.x
'

cfa_tv_sem <- sem(cfa_tv_model, data = cfa_tv, estimator = "MLR")
summary(cfa_tv_sem, fit.measures=TRUE, standardized=TRUE)
```
The above model indicates good fit across all fit indices! Chi-squared has moved above the significant threshold, though still low, SRMR increased though is still below the threshold. CFI and TLI are both improved, similarly across all RMSE indicators. The paths visualisation is similar to previous visualisations. There are some suggested improvements in the model, however disconnecting mitigations 1 from cases 0 is unlikely to be represented of the true causal path.

```{r}
reliability(cfa_tv_sem)
```
All reliability scores are above the threshold.

```{r}
resid(cfa_tv_sem, "cor")
```
There appears to be no highly significant difference between observed and implied correlations, stringency sitting just above threshold values, though the statistics indicate the model tends over predict correlation resulting in mostly negative values  [@michaelhallquistIntroductorySEMUsing2018].

Overall indications are that a time varying model is the most accurate, particularly when there is a zero state present where no mitigation was taken, this could potentially relate to a need to lead and lag some variables. Hernan suggests that in order to undertake investigation into time varying causal models, g-methods must be implemented. [@hernanCausalInferenceWhat]

## G-methods
Attempts were made to incorporate g-methods based on counterfactual consistency and inverse weighting [@naimiIntroductionMethods2016] as described by Hernan, using the gfoRmula package [@linGfoRmulaPackageEstimating2019] however, these methods require a much deeper understanding of statistics, expert knowledge of the subject matter and best practice. The referenced paper [@naimiIntroductionMethods2016] opens that uptake by professional epidemiologists was hampered by the complexities understanding concepts and technical details.

First the structure of the data needs to be modified into the format ID, time index, covariates, treatment, outcome.
For the analysis this will be, iso_code, weekoneplus, covariates (log of new cases per million, median age), stringency index, log of new deaths per million.

```{r}
 cvd_g <- cvd_100c %>% 
  mutate(weekoneplus = weekoneplus -1) %>% 
  filter(iso_code != "ECU", iso_code != "UGA", iso_code != "BEN",
         iso_code != "CTU", iso_code != "FIN", iso_code != "ESP", iso_code != "LTU") %>% 
  mutate(logndpm = log(new_deaths_per_million), logncpm = log(new_cases_per_million)) %>% 
  mutate_at(vars(median_age, aged_65_older, aged_70_older, logncpm, logndpm, stringency_index.x), rescale, to = c(0,10)) %>% 
  select(iso_code, weekoneplus, median_age, logncpm, logndpm, stringency_index.x) %>% 
  na.omit()
  
cvd_g[cvd_g$logndpm < -1000, "logndpm"] <- 0
cvd_g[cvd_g$logncpm < -1000, "logncpm"] <- 0

cvd_g$iso_code <- as.factor(cvd_g$iso_code)
cvd_g_n <- cvd_g
cvd_g_n$iso_code <- as.numeric(cvd_g_n$iso_code)

gmethdf <- cvd_g_n %>% 
  filter(weekoneplus <= 5) %>% 
  mutate(weekoneplus = weekoneplus -1) %>% 
  filter(iso_code != 10, iso_code != 42, iso_code != 3, iso_code != 124, iso_code != 148, iso_code != 78, iso_code != 90, iso_code != 92, iso_code != 96, iso_code != 129)


```

Transformation complete now into model structure. [@linGfoRmulaPackageEstimating2019]

```{r, eval = FALSE}

gformula_continuous_eof(obs_data = gmethdf,
                        id = "iso_code",
                        time_name = "weekoneplus",
                        outcome_name = "logndpm",
                        covnames = c("logncpm", "stringency_index.x"),
                        basecovs = "median_age",
                        covtypes = c("normal", "normal"),
                        histories = c(lagged),
                        histvars = list(c("logncpm", "stringency_index.x")),
                        covparams = list(covmodels = c(
                          logncpm ~ lag1_logncpm + lag1_stringency_index.x + weekoneplus,
                          stringency_index.x ~ lag1_logncpm + weekoneplus
                        )),
                        ymodel = logndpm ~ median_age + logncpm + lag1_logncpm + stringency_index.x + lag1_stringency_index.x,
                        seed = 222
                        )

```
Unfortunately I could not trouble shoot the error "Error in int_result/ref_mean : non-numeric argument to binary operator" despite numerous modifications. Further work will be required to implement this model type.

# Outcomes

## Conclusions
It is evident from the analysis in [Appendix B](#appendix-b) that the structure and casual pathways implied by the previous research effort [@dannyleihanCOVID19COVIDResearch202007272020] induced many opportunities for systemic bias and few attempts to mitigate these. The inability to model the implied DAG in SEM aids to verify this assumption that it is unlikely the inferred casual pathways were reflected in the observational data. Later efforts to develop a model that could aid in developing future research efforts were necessarily quite simplified structures. Most efforts met with minimal success with a mix of good and poor fit indications. The final time varied effort revealed a potential causal structure that is reflected in the observational data, however while most indices indicated good fit, most were still close to acceptable threshold values. Unfortunately modelling utilising g-methods methods was unsuccessful, however this approach is a potential candidate for evaluating a full time varied model effectively.


## Reflection
The deeper I dove into Structural Equation Modelling and Causal Inference the more I realised the topic of COVID-19 is far too complex and the data too incomplete or poorly recorded for the application of these methods to be truly effective. While these methods are requirements to understanding the pandemic, due particularly to the large amount of observational data available, their application by an amateur and with limited data is unlikely to see any positive outcomes.

That said, of the available methods these were by far the most interesting to me, I chose to peruse this method based on that interest. The method opens understanding into not only new statistical methods as observed in other methods, but frameworks for identifying, communicating and assessing complex problems utilising DAGs and causal inference, topics which I will continue to investigate. To this end I kept on digging my hole deeper, I have learnt a great deal however the outcomes could have been improved. I believe including other areas of statics would have potentially improved overall outcomes on reflection, particularly looking into time series and accurately interpret lead and lag of variables, or potentially create a multi-level SEM model.

Overall, I'm glad I chose this method for the learning opportunities I gained, achieving a just passable fit on the complex time varied model was enough of an achievement. As long as I interpreted the outcomes correctly.
# References

<div id="refs"></div>

# Apendicies

## Appendix A
## Appendix A
*Implied Structure*
Repeated instances of the same implication in a different section are not repeated. The implications measured and or posited through analysis are highlighted in bold

#### Introduction
1. **Total cases per million population varied between locations due to measured and unmeasured factors**
2. Extremely small population countries had very high case/population due to their low population
3. **Total deaths per million population is less dependent on cases/population than other factors**
4. Extremely small population countries had very high deaths/population due to their low population
5. **The responses a countries government makes in response to covid are causes for variation between cases and deaths per population**
6. More responses indicate a "better" response

#### Country Based Age Influence
7. Age distribution between countries is a result of many unobserved factors
8. **Age of a population effects the outcomes during pandemic's epidemics and emergencies such as COVID-19**
9. **Conditioning age to higher values is associated with poorer COVID-19 outcomes**
10. Variation in COVID-19 outcomes is not only associated with age
11. **The total deaths are associated with an increased time since initial COVID-19 infections**
12. Industrialized nations are associated with a higher median age
13. Richer countries may be associated with a higher median age. (We can take richer here to mean GDP per capita)
14. Recording of death due to COVID may be subject to error
15. Methods of classifying deaths due to covid may have contributed to causing that error
16. Conditioning on age does not rule out associations between increased risk and other factors

#### Patient Case Based Analysis
17. Being the first country exposed to COVID is associated with comprehensive data collection
18. Disclosure of information varies between countries
19. Is there an association between COVID symptoms and chronic diseases
20. Is increased age associated with chronic disease
21. Is increased age associated with weakened immune system and therefore more susceptible to COVID
22. Conditioning reproduction number to 1 is causally associated with disease spread (transmission)
23. Conditioning on reproduction number 0 is associated with and end of transmission
24 High reproduction rate causes increase in pharmaceutical (medical) interventions
25. Medical interventions are associated with reduced transmission
26. Symptom onset is associated with time since infection
27. Longer time periods between exposure and onset of symptoms is a cause of transmission
28. Identification of symptoms for COVID is associated with identification of symptoms for the flu
29. COVID patients with poor outcomes is caused by the immune system attacking healthy cells (immune disorder)
30. Immune disorder is associated with infection
31. Immune disorder is associated with organ failure
32. Mean of age distribution is associated with true age
33. **Conditioning location to the United States is associated with higher age**
34. **Conditioning location the United States is associated with a lower rate of infection at lower ages**
35. Conditioning location to the United States is associated with increased cases
36. Symptoms are associated with chronic disease
37. Symptoms are associated with COVID
38. COVID diagnosis is negatively associated with the presence of symptoms due to chronic disease

Conditioning for individuals with COVID;
39. **Conditioning symptoms to pneumonia is associated with chronic disease**
39. **Conditioning symptoms to acute respiratory is associated with chronic disease**
40. **Conditioning symptoms to mild is associated with chronic disease**

41. symptoms associated with chronic disease may be associated with age

#### Global Factors Influencing Variation in Healthcare Effectiveness
42. Higher deaths is associated with poorer outcomes
43. Higher cases is associated with poorer outcomes
44. Increased stringency is associated with poorer outcomes
45. More recent dates are associated with poorer outcomes
46. Maximum cases causes maximum deaths
47. Health equality may be measure of the quality of healthcare and or maximum cases and or maximum deaths
48. Basic welfare may be measure of the quality of healthcare and or maximum cases and or maximum deaths
49. Quality of basic healthcare may be measure of the quality of healthcare and or maximum cases and or maximum deaths
50. Access to public healthcare may be a measure of the quality of healthcare and or maximum cases and or maximum deaths
51. Healthcare expenditure as a percentage of GDP may be measure of the quality of healthcare and or maximum cases and or maximum deaths
52. **Basic welfare is associated with median age**
53. **Stringency index is associated with deaths/cases per million population**
54. **Lead/lag time between maximum cases and deaths is associated with deaths/case per million**
55. **Quality of healthcare statistics were not associated with deaths/case per million population**

#### Effectiveness of Response
56. Mitigations are associated with improved COVID outcomes
57. Social distancing is associated with mitigation
58. Closing schools is associated with mitigation
59. Shutting down restaurants is associated with mitigation
60. Controlling traffic is associated with mitigation
61. Mitigations are associated with reduced infection rates
62. Traffic control may be associated with confirmed cases
63. Apple mobility metrics are associated with traffic control

#### Global Factors Influencing Variation in Response and Government
64. Deaths prior to restriction are not associated with deaths after restrictions
65. Public Trust in politicians is associated with effectiveness of response
66. Public Government Effectiveness is associated with effectiveness of response
67. Effectiveness of response may be associated with deaths prior to and/or after restrictions change
68. Conditional restriction levels were associated with increased deaths compared to previous 21 day period
69. **Effectiveness in government is not associated with the above variables**


## Appendix B
### Introduction
The following figure indicates the casual graph implied in the introduction of the report, the implied structure contains many sources of systematic bias. The first challenge is that the measured statistics are subject to error and do not represent the true occurrences. There are likely to be common causes of error in measuring cases and deaths due to COVID, e.g. asymptomatic patients and testing strategies. Additionally, being diagnosed with COVID is likely to influence your chance of death and weather your death will be recorded as COVID related, the bias implied by this structure is dependent differential bias [@hernanCausalInferenceWhat] and causes bias even under the null making it quite challenging to negate. Further, when trying to determine the effect of population on deaths there is confounding due to the common cause of response, similarly, there is confounding if any unmeasured factor affecting cases and deaths is common. There is also potential for selection bias at the collider deaths, as we would be conditioning on recorded deaths in analysis. This shows that the inferences made in the introduction should be reassessed. Further investigation of Cusal DAGs is available in [Appendix B](#appendix-b)

![DAG](./dags/intro.png)

### Country Based Age Influence
When investigating the effect of age on deaths, conditioning age on higher values opens the path to other unmeasured effects on age identified. Previously identified measurement bias is consistent in these analyses. Applying certain regression methods to age is a viable method of reducing the effect of confounding due to common cause of age, however the measurement bias is still present.

![DAG](./dags/agecountry.png)

### Patient Case Based Analysis
The issue with continually building on prior inferences without a framework for evaluating their structure becomes more evident here. In verifying the reason for using this dataset we instead identify two potential shared causes for measurement error; disclosure and time since first case. Additionally, as this research in focused on patient data, the location variable is introduced, a common cause of many of the observations and therefore likely to confound any analysis. It is identified that we can condition on this variable for example selecting only patient from the USA, which would potentially reduce confounding at the risk of introducing selection bias, and observe changes in distributions, however the research did not utilise this in regression. The directionality of the graph becomes quite complex with the introduction of chronic disease, introducing another source of differential dependent error. In determining if there is a connection between chronic disease and particular symptoms, conditioning symptoms opens the collider inducing selection bias, age appears to act as an additional confounder.

![DAG](./dags/patient.png)


### Factors and Effectiveness
All the factor analyses introduce selection biases as they select for varying conditions of outcome variables or deaths, in addition to the other bias's observed previously. The chosen observed variables are also likely to be associated with other parts of the DAG acting as common cause confounders.

![DAG](./dags/effects.png)

### Time Varying Treatment
In both the patient based and response investigations, time varying treatment bias is introduced into the model, the complexity in displaying this prevents visualisation. In patient based investigation, the bias is due to the effect of the change in quality of treatment as understanding of the virus improved effecting the symptoms and observed. In the response investigations, as the response effects both cases and future response we see a similar effect.

### Full Implied Structure
The implied structure by the research is quite flawed and has many inherent sources of systematic bias in the experiments undertaken which were not accounted for. The structure is complex developed as the research progressed, further detailing of bias in this model is unlikely to be beneficial.

![DAG](./dags/full.png)
